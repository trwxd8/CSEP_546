Loss calculated for layer count:1 node count: 25 stepSize:0.2 Momentum: False
train0 0.11549538564275093 greater than 1
test0 0.09855629860445002
train5 0.060132031301752896 greater than 0.06303621715378852
test5 0.0669956276630196
train10 0.05237745154578857 greater than 0.05345902634636749
test10 0.051427837387446794
train15 0.048332986667063184 greater than 0.049018232130495935
test15 0.04402816038916399
train20 0.045068342200832445 greater than 0.04572464974844211
test20 0.039312490600431974
train25 0.041759973214616504 greater than 0.04246542500704774
test25 0.034759927789091254
train30 0.038556926601111485 greater than 0.03910661204921971
test30 0.032444785354710105
train35 0.036625212507839275 greater than 0.036948128202521344
test35 0.03132991460930731
train40 0.03507925760954457 greater than 0.03537887332851579
test40 0.03059515391540299
train45 0.033684666300940316 greater than 0.03395174781433372
test45 0.03030976986870088
train50 0.03252476206044685 greater than 0.032714510894305736
test50 0.030508149466510162
train55 0.03168067994586876 greater than 0.03184263428060993
test55 0.0306989800085053
train60 0.030917871840638725 greater than 0.031062103312522106
test60 0.03102825052570202
train65 0.030238340916970603 greater than 0.030392363578164643
test65 0.032162644473390276
train70 0.029603215398157592 greater than 0.029693490633378047
test70 0.03364681411408609
train75 0.028640181221795687 greater than 0.02884597632394481
test75 0.03510943305985166
train80 0.027788521497319817 greater than 0.027957767733616967
test80 0.0349021009093695
train85 0.027018793394941697 greater than 0.027166557257045042
test85 0.03421132494103629
train90 0.02635206143724914 greater than 0.026495888936029065
test90 0.033823263407578824
train95 0.025674085650771224 greater than 0.025768365302145078
test95 0.03340168267803116
train100 0.025375107995462966 greater than 0.02548122491784748
test100 0.03357825071488097
train105 0.02512872028719622 greater than 0.02521303881789592
test105 0.03328794482975048
train110 0.024245182436112053 greater than 0.02440794923148742
test110 0.03314741411949265
train115 0.023584026041161166 greater than 0.023686036997055442
test115 0.03355237190534405
train120 0.023253383541771318 greater than 0.02331274035127158
test120 0.03385023718515038
train125 0.022919361434686678 greater than 0.023018919810248745
test125 0.03339172137923695
train130 0.022472545020526313 greater than 0.02257161118309045
test130 0.03287200228331801
train135 0.021995266519283626 greater than 0.02207358393477242
test135 0.03320435474726801
train140 0.02160324861973196 greater than 0.02169900791258671
test140 0.032925900410457856
train143 0.021379268838753556 greater than 0.021370643134828792
test143 0.03324470684635842
0 Accuracy:0.9207920792079208 Lower Bound:0.9055876592926039 Upper Bound:0.9359964991232378
Loss calculated for layer count:1 node count: 25 stepSize:0.2 Momentum: True
train0 0.11549538564275093 greater than 1
test0 0.09855629860445002
train5 0.05961392902892286 greater than 0.06272592073159436
test5 0.06983963088879573
train10 0.051444551868080154 greater than 0.05267313938452397
test10 0.04685394839756588
train15 0.0455254818622107 greater than 0.046686273191436235
test15 0.039835890093907006
train20 0.04103607520810619 greater than 0.04178358622555767
test20 0.03408373362011445
train25 0.03820565558767137 greater than 0.03864771679420943
test25 0.032671063020766895
train30 0.03684179158814784 greater than 0.03707505363430707
test30 0.03178739017726663
train35 0.0354643183664697 greater than 0.035752832663943884
test35 0.0316271886954838
train40 0.03402144313115302 greater than 0.034239698736491235
test40 0.0340712512609513
train45 0.03300577763082624 greater than 0.03334145835781224
test45 0.03530497339265352
train50 0.031598410373705324 greater than 0.0318185904220561
test50 0.03456425705672183
train55 0.030873864544290443 greater than 0.031026270137692637
test55 0.044959870033554235
train60 0.030115188142594607 greater than 0.03023150418796505
test60 0.04665009653258744
train65 0.02889318278149756 greater than 0.02902346085786959
test65 0.0332074931553837
train70 0.0278970894070833 greater than 0.028147662781104886
test70 0.033294773125697286
train75 0.026689751823821894 greater than 0.026868362262119933
test75 0.032617549221688656
train80 0.02599271131177167 greater than 0.026047807164094116
test80 0.03339761979554343
train85 0.02557138436679131 greater than 0.02566311489674212
test85 0.033089131299572326
train88 0.025085505165241887 greater than 0.02502847239199271
test88 0.03511559338252295
0 Accuracy:0.9133663366336634 Lower Bound:0.897529421057252 Upper Bound:0.9292032522100748
Loss calculated for layer count:1 node count: 25 stepSize:0.2 Momentum: False
train0 0.11969526435337625 greater than 1
test0 0.10266547427835258
train5 0.06335672100289076 greater than 0.06666627679411152
test5 0.07348458330842006
train10 0.05481045418256524 greater than 0.055970573789440724
test10 0.0604501556389527
train15 0.05074735151681181 greater than 0.05140273994248291
test15 0.05218803187486944
train20 0.04806397471200911 greater than 0.048549623264106445
test20 0.04688469028968972
train25 0.045644745277585476 greater than 0.046143273782148955
test25 0.04256120316624452
train30 0.04302066576048849 greater than 0.04356346028979479
test30 0.03884902626788145
train35 0.04030621938783694 greater than 0.040845901683210374
test35 0.03619816506203152
train40 0.03778487419417553 greater than 0.038251879583238176
test40 0.034860126286031294
train45 0.03579867307715293 greater than 0.03615398356418231
test45 0.03411983933462123
train50 0.03406511475229903 greater than 0.03440764873301003
test50 0.033712053162087294
train55 0.03257669840195392 greater than 0.03282368987371549
test55 0.03278832995159639
train60 0.031286446578863696 greater than 0.03155039585960518
test60 0.03221258654776331
train65 0.030137110596898647 greater than 0.030328313472295556
test65 0.03189240811133155
train70 0.029307001056582828 greater than 0.02944505754609268
test70 0.031662548177814255
train75 0.0287856669843879 greater than 0.028879479569025344
test75 0.031881437284698014
train80 0.028147240192552464 greater than 0.028285543295448037
test80 0.03228229925147733
train85 0.027585746310397913 greater than 0.027703486225070663
test85 0.0337008573826413
train90 0.026948949071470153 greater than 0.02711028811119612
test90 0.033854609560223285
train95 0.026118617694881757 greater than 0.026273691780392724
test95 0.03305369258313236
train100 0.025289491080891357 greater than 0.025464386383720512
test100 0.032164801633117426
train105 0.024433356551408 greater than 0.024593164511092055
test105 0.03204458153398781
train109 0.024125247572268686 greater than 0.0240222919531702
test109 0.03275688968048528
1 Accuracy:0.9174917491749175 Lower Bound:0.9020016379834073 Upper Bound:0.9329818603664277
Loss calculated for layer count:1 node count: 25 stepSize:0.2 Momentum: True
train0 0.11969526435337625 greater than 1
test0 0.10266547427835258
train5 0.07121411094441014 greater than 0.07494409096906855
test5 0.08095394600828264
train10 0.06104004255656744 greater than 0.06269106500653761
test10 0.06116001831011779
train15 0.05442886748967598 greater than 0.055491728004161675
test15 0.0516711672237637
train20 0.05129894148063155 greater than 0.05196144494228433
test20 0.048991441410758285
train25 0.04821415467623811 greater than 0.0489859566762404
test25 0.047678885595311755
train27 0.04774415478020206 greater than 0.04746223990752825
test27 0.04782849185344955
1 Accuracy:0.8745874587458746 Lower Bound:0.855941837062247 Upper Bound:0.8932330804295022
Loss calculated for layer count:1 node count: 25 stepSize:0.2 Momentum: False
train0 0.1208271393851721 greater than 1
test0 0.10471212935764404
train5 0.06542234669529426 greater than 0.0692136162015301
test5 0.08018149960332571
train10 0.056230273572034674 greater than 0.05746571519859668
test10 0.06874400906674359
train15 0.051804959724394556 greater than 0.052530742651266775
test15 0.05994602996860059
train20 0.048819431741757506 greater than 0.04935527519851319
test20 0.05346754016203014
train25 0.04636431017464714 greater than 0.04683355308468126
test25 0.048671398183651016
train30 0.04402705314750822 greater than 0.044505315366323996
test30 0.04442562590006968
train35 0.04154337087120062 greater than 0.04202871357238431
test35 0.040652157211572934
train40 0.039347949521825416 greater than 0.03975410676057378
test40 0.03763297287817171
train45 0.03750454872423203 greater than 0.03787231396913484
test45 0.0356617965528479
train50 0.035660934059211016 greater than 0.036022097659868586
test50 0.034354219694898776
train55 0.033893142810363 greater than 0.03426615163280988
test55 0.033190585896819856
train60 0.03217997799022595 greater than 0.032469800419527586
test60 0.031789897221596204
train65 0.030917837165688005 greater than 0.031148103484902098
test65 0.030651542625521756
train70 0.029914583582244157 greater than 0.030104553977576717
test70 0.03016021571978802
train75 0.02899048769976478 greater than 0.029162575333000477
test75 0.030262102310911254
train80 0.028264600024855757 greater than 0.02839861758783663
test80 0.03053033185388338
train85 0.02759743388246927 greater than 0.02772747003177935
test85 0.031027716754452844
train90 0.02691953588632447 greater than 0.027062381272863322
test90 0.031894110168215146
train95 0.026288607312391257 greater than 0.026400205418576985
test95 0.03245682234466709
train100 0.025851893365776635 greater than 0.025937517234968004
test100 0.03266673299872173
train105 0.025135377289548854 greater than 0.025305703848947054
test105 0.032804815483046805
train110 0.024424567127674265 greater than 0.02457512874629899
test110 0.03324451477202557
train115 0.02391978049308654 greater than 0.023999344719457073
test115 0.03275246680887235
train119 0.023844425172481237 greater than 0.02382076341012943
test119 0.032407717508941856
2 Accuracy:0.915016501650165 Lower Bound:0.8993169761328473 Upper Bound:0.9307160271674827
Loss calculated for layer count:1 node count: 25 stepSize:0.2 Momentum: True
train0 0.1208271393851721 greater than 1
test0 0.10471212935764404
train5 0.07795937935380623 greater than 0.08095171159113523
test5 0.08022442974239816
train10 0.06877001940322311 greater than 0.06967138914596133
test10 0.08305112262184493
train15 0.06257208581703222 greater than 0.06382181095487313
test15 0.06776870825430643
train20 0.05982743289638422 greater than 0.060206698563966224
test20 0.06626300195112383
train24 0.05639395211672361 greater than 0.05624635369772514
test24 0.061089996477599474
2 Accuracy:0.8333333333333334 Lower Bound:0.8123517376821695 Upper Bound:0.8543149289844972
Loss calculated for layer count:1 node count: 25 stepSize:0.2 Momentum: False
train0 0.12306170783507261 greater than 1
test0 0.10851039265966714
train5 0.06778942033239813 greater than 0.0719065788589244
test5 0.08503184595906392
train10 0.058188064715354315 greater than 0.05941522415525088
test10 0.07219699211561899
train15 0.05391032240185115 greater than 0.05460087582589748
test15 0.06347219414924127
train20 0.05118921667815653 greater than 0.05165554893949869
test20 0.05755745524367795
train25 0.04925661172210135 greater than 0.04959890597811954
test25 0.05372517888434738
train30 0.04777460005248337 greater than 0.04804605004452566
test30 0.0511532622834684
train35 0.046529717129987505 greater than 0.046768333802480924
test35 0.04931656610219698
train40 0.04536476942551967 greater than 0.04559508433187831
test40 0.04793772442337156
train45 0.04425822877564196 greater than 0.04447166168031067
test45 0.04681499589694318
train50 0.04323164067252341 greater than 0.0434341017538022
test50 0.045764941511037244
train55 0.04222143536217133 greater than 0.04242413092931936
test55 0.04460751209851158
train60 0.04118626488191807 greater than 0.04139719348028215
test60 0.04320848271908039
train65 0.040079930194506806 greater than 0.040310928510520726
test65 0.04154475500136515
train70 0.03873312316775682 greater than 0.03904161903724537
test70 0.039741828457794476
train75 0.03687828111090065 greater than 0.03726408441306117
test75 0.038254326954651106
train80 0.03511218975065158 greater than 0.03544134877609711
test80 0.037308530651286226
train85 0.033594751414864676 greater than 0.03388366565737391
test85 0.036419312922901875
train90 0.03225127905459751 greater than 0.032509956510122624
test90 0.035512078714459085
train95 0.03098351887306657 greater than 0.031235975800808804
test95 0.034675602607844046
train100 0.029697966546095193 greater than 0.029959035690876205
test100 0.033761870081383684
train105 0.028236967282312914 greater than 0.028551683153727556
test105 0.033195857131162014
train110 0.026865050419546593 greater than 0.02710915710899372
test110 0.03322890304984979
train115 0.025879645333877748 greater than 0.0260455834255482
test115 0.033754306003062486
train120 0.02496866196492293 greater than 0.025166952902307638
test120 0.03439523580177972
train125 0.02408244671518031 greater than 0.024255208356758005
test125 0.03424924934120131
train130 0.023278920262838412 greater than 0.023428129761692538
test130 0.033504935154642417
train135 0.02264302443660301 greater than 0.02276458382024745
test135 0.032420761428253494
train140 0.0220687022796125 greater than 0.022146193281045612
test140 0.031551464887140605
train145 0.02153659854427938 greater than 0.02169457687477381
test145 0.031007709986580582
train150 0.020854104385685673 greater than 0.020964988245186212
test150 0.03075236243590233
train155 0.02033854270149624 greater than 0.020447061234228486
test155 0.03085220025522522
train160 0.019517124831960476 greater than 0.019821866701137274
test160 0.03107394952881437
train164 0.019356396908383755 greater than 0.01929409966627949
test164 0.03130926526939376
3 Accuracy:0.9224422442244224 Lower Bound:0.907383561948374 Upper Bound:0.9375009265004709
Loss calculated for layer count:1 node count: 25 stepSize:0.2 Momentum: True
train0 0.12306170783507261 greater than 1
test0 0.10851039265966714
train5 0.06764573100246216 greater than 0.0718196902712934
test5 0.08699118062532067
train10 0.05794699422629521 greater than 0.05917645335573667
test10 0.07185648650008336
train15 0.05363185174873509 greater than 0.054319894510337655
test15 0.06330500514595913
train20 0.05096273471571231 greater than 0.0514164464668678
test20 0.05765066193160524
train25 0.04907096550855269 greater than 0.04941030693373432
test25 0.05378903699029201
train30 0.04753049919636664 greater than 0.04782600074526991
test30 0.05088402194426032
train35 0.046015859323043876 greater than 0.046332728202541765
test35 0.04857359665626274
train40 0.04424968945202957 greater than 0.044628691466935
test40 0.046655609864580366
train45 0.04217920393990039 greater than 0.04261044844292142
test45 0.044833622542954546
train50 0.040067781430195556 greater than 0.040472601727208915
test50 0.04269561882956263
train55 0.03826570036318072 greater than 0.03859761199901189
test55 0.040317159941079005
train60 0.036520079581508276 greater than 0.03689730222751806
test60 0.03792383964521842
train65 0.03453597534217929 greater than 0.034896287164724954
test65 0.03632276940292815
train70 0.03284546551100745 greater than 0.033164941921777026
test70 0.035328461345160996
train75 0.031307612727523554 greater than 0.03163215489640586
test75 0.03441133619352486
train80 0.029620508922932033 greater than 0.02994252764288857
test80 0.033708727637359166
train85 0.028035028473624515 greater than 0.02836734838559846
test85 0.0333868376617618
train90 0.02693100006131469 greater than 0.02707464189248413
test90 0.03343807040637412
train95 0.02643185829261136 greater than 0.026557426052729708
test95 0.03328922887981444
train100 0.02569296945759919 greater than 0.02584980138982437
test100 0.033375950359992634
train105 0.02504217773900233 greater than 0.02511510945844488
test105 0.03305184724756507
train110 0.024186169094386707 greater than 0.02431077403138245
test110 0.03353419768004171
train115 0.02368396789473737 greater than 0.023774482286757662
test115 0.03371017421000456
train120 0.023214661277759004 greater than 0.023305021777532218
test120 0.03388184019149269
train125 0.022686836597571453 greater than 0.022814423091762636
test125 0.033966560449229924
train130 0.022561146976316268 greater than 0.022118866564864104
test130 0.03373625211778625
3 Accuracy:0.9141914191419142 Lower Bound:0.8984229805385732 Upper Bound:0.9299598577452551
Loss calculated for layer count:1 node count: 25 stepSize:0.2 Momentum: False
train0 0.12629386175458013 greater than 1
test0 0.1175297450335986
train5 0.07507374034753615 greater than 0.08007344379102484
test5 0.06114023973439022
train10 0.06270906417343684 greater than 0.06420601170103782
test10 0.051587916740122544
train15 0.05780863121031834 greater than 0.05857145636878628
test15 0.04841605209951744
train20 0.05480495856917809 greater than 0.05532206332321921
test20 0.04666682720725115
train25 0.05262705744148754 greater than 0.05301800330089859
test25 0.045358806694230897
train30 0.05091457587127768 greater than 0.051229065020023314
test30 0.04432328581100768
train35 0.04950542517947954 greater than 0.0497680149568484
test35 0.04349284005323184
train40 0.048303101571325904 greater than 0.048530941156708564
test40 0.04280453866766352
train45 0.047228831734096366 greater than 0.04743687404256803
test45 0.04220828146716724
train50 0.046213286519748556 greater than 0.04641486199881976
test50 0.041656408167737975
train55 0.04519415364027774 greater than 0.04540046911830373
test55 0.041067769399018926
train60 0.04414237347281256 greater than 0.044355369228738145
test60 0.040292411610317026
train65 0.04302936659631705 greater than 0.043262280963572645
test65 0.03913467839116927
train70 0.04171453727334671 greater than 0.04200088816448786
test70 0.03753840057078703
train75 0.04016081282964105 greater than 0.04048040839634395
test75 0.03573117634001319
train80 0.038584720892451366 greater than 0.03889294225818566
test80 0.03421537278527633
train85 0.037064564027820684 greater than 0.03736781748695348
test85 0.03303789844696725
train90 0.03556429298626528 greater than 0.03587195118170882
test90 0.03206928421184541
train95 0.03388795250078581 greater than 0.03422288082255583
test95 0.03131651870441581
train100 0.032205448727496484 greater than 0.03257113378731611
test100 0.030560729580954703
train105 0.030506843464237418 greater than 0.03083002054046965
test105 0.030017595966138032
train110 0.029105259406286034 greater than 0.029371557919562488
test110 0.029792611488677477
train115 0.02784893838466861 greater than 0.028088480002186604
test115 0.029750474065936196
train120 0.026664560813319207 greater than 0.026894258151322684
test120 0.0298008233868453
train125 0.025770611357178702 greater than 0.025904469225749675
test125 0.030052112759078223
train130 0.024839528234164243 greater than 0.025112209198346277
test130 0.030258299536127617
train135 0.02408747617345146 greater than 0.024218154905090248
test135 0.030382277180470006
train140 0.023288998882829162 greater than 0.023497337616790792
test140 0.030737707233210794
train145 0.022161742848987972 greater than 0.022385216486372116
test145 0.032363267142843544
train150 0.02139951183473793 greater than 0.0213911763511938
test150 0.03191788254587224
4 Accuracy:0.9174917491749175 Lower Bound:0.9020016379834073 Upper Bound:0.9329818603664277
Loss calculated for layer count:1 node count: 25 stepSize:0.2 Momentum: True
train0 0.12629386175458013 greater than 1
test0 0.1175297450335986
train5 0.08183866303188371 greater than 0.08584421310234965
test5 0.06162342931101126
train10 0.06532965313130291 greater than 0.067603574930072
test10 0.05196089924548748
train15 0.05990312592034698 greater than 0.06037357029522381
test15 0.0495454360122898
train20 0.05697309537843266 greater than 0.05746659958708088
test20 0.047411889314493534
train25 0.05370974262169879 greater than 0.0543151864753125
test25 0.04632366784895353
train30 0.050890643740793017 greater than 0.051374820052570894
test30 0.0472004162963728
train35 0.048239907761643434 greater than 0.04899436477240358
test35 0.04143022416064721
train40 0.04390779024736368 greater than 0.04439820865572916
test40 0.039185810678023555
train45 0.04147706872317584 greater than 0.041755926646753046
test45 0.03852000498316915
train50 0.039334010596905104 greater than 0.039975124400723955
test50 0.038099917585113094
train55 0.037519647521363074 greater than 0.03803141304223851
test55 0.03873295729573019
train59 0.03663052051064054 greater than 0.036541779385980945
test59 0.03762033602774257
4 Accuracy:0.9018151815181518 Lower Bound:0.8850624471145347 Upper Bound:0.9185679159217688
