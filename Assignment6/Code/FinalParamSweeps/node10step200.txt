Loss calculated for layer count:1 node count: 10 stepSize:0.2 Momentum: False
train0 0.11801446788171274 greater than 1
test0 0.10176636924192242
train5 0.061020690695338574 greater than 0.0638595967549972
test5 0.06783852359455868
train10 0.05349033831040527 greater than 0.05454010234249317
test10 0.05270984818168652
train15 0.04960526026466012 greater than 0.05023969406360136
test15 0.04558445018581872
train20 0.047187066088537406 greater than 0.04758391211302994
test20 0.041873231412193845
train25 0.04556298743300886 greater than 0.04585349815375464
test25 0.04009013968205366
train30 0.04429971564948463 greater than 0.044531081711633266
test30 0.039008259864284925
train35 0.04318714151392926 greater than 0.043410864416961945
test35 0.03813936422072569
train40 0.04206183217467434 greater than 0.0422911327616917
test40 0.03742018863435028
train45 0.04094137810378818 greater than 0.04114823491589827
test45 0.03687037349670438
train50 0.0399170524517002 greater than 0.0401155000151931
test50 0.03649780880284007
train55 0.03899432785575434 greater than 0.0391719042944986
test55 0.03623511920322594
train60 0.038159139759971886 greater than 0.03832302607687481
test60 0.03602441557084165
train65 0.03719411897905929 greater than 0.0374569792969759
test65 0.03511027416352861
train70 0.03521128352632155 greater than 0.03557578413118811
test70 0.033733261267387134
train75 0.03345080286323847 greater than 0.033768618222151096
test75 0.033214623483395204
train80 0.031903535147891716 greater than 0.03223059840998044
test80 0.03355385670619429
train85 0.030743547606437355 greater than 0.03092946795139585
test85 0.034304633199639646
train90 0.029697668421144335 greater than 0.029910351397733705
test90 0.03598449514216075
train95 0.02870822670920669 greater than 0.02890148356397998
test95 0.03761680963382105
train100 0.027812311349161754 greater than 0.027964034613047785
test100 0.038821790504552374
train105 0.02720802151612537 greater than 0.02731618833565926
test105 0.039257658726702935
train110 0.026856653257368062 greater than 0.02689391534534962
test110 0.039610425053513296
train115 0.026295546528918273 greater than 0.02637035061760435
test115 0.03785730310934659
train120 0.025631606620418742 greater than 0.02578286142965247
test120 0.03870605402377058
train121 0.02567984218280416 greater than 0.025631606620418742
test121 0.04155671760256449
0 Accuracy:0.8886138613861386 Lower Bound:0.870901483158072 Upper Bound:0.9063262396142052
Loss calculated for layer count:1 node count: 10 stepSize:0.2 Momentum: True
train0 0.11801446788171274 greater than 1
test0 0.10176636924192242
train5 0.06047356460577905 greater than 0.06342312761946431
test5 0.06793653399005788
train10 0.052857798196461865 greater than 0.053942407931818356
test10 0.05138230705767361
train15 0.04861423171618584 greater than 0.04935951593243818
test15 0.042631456349132846
train20 0.04462328903905833 greater than 0.04548975882438609
test20 0.036742292778620525
train25 0.04079891600059154 greater than 0.04147392270475835
test25 0.035867834051109895
train30 0.038185709644737914 greater than 0.03858450933448767
test30 0.03215338463657513
train35 0.03663346573222165 greater than 0.0369427054075972
test35 0.030258966607970537
train40 0.03517719162348054 greater than 0.03543466422046073
test40 0.031097010937905834
train45 0.03398955227078424 greater than 0.034229927036754496
test45 0.029768066742024417
train50 0.03323634555849456 greater than 0.033349999763438914
test50 0.02862359898319406
train55 0.03262741922167081 greater than 0.0327582572554488
test55 0.029184337445932768
train60 0.032095590917846084 greater than 0.032229213976578096
test60 0.02969081847912867
train65 0.03140595601318441 greater than 0.03153682762204079
test65 0.029805574786572423
train70 0.030740971998876144 greater than 0.030951458793518155
test70 0.029579963687022603
train72 0.03066414753425386 greater than 0.030663452622765024
test72 0.0292011779829085
0 Accuracy:0.9224422442244224 Lower Bound:0.907383561948374 Upper Bound:0.9375009265004709
Loss calculated for layer count:1 node count: 10 stepSize:0.2 Momentum: False
train0 0.12050273421095377 greater than 1
test0 0.10497056288278392
train5 0.06427349522663604 greater than 0.06741627580023433
test5 0.07581326436236244
train10 0.056197812666124745 greater than 0.057292536877050736
test10 0.06375943869801551
train15 0.05224003127818042 greater than 0.05291333177071916
test15 0.05347562477370895
train20 0.049183500913290754 greater than 0.049759184687098536
test20 0.04700895920025855
train25 0.046500713064738394 greater than 0.04699073232423094
test25 0.04226380150621584
train30 0.04409198672319778 greater than 0.04452705416587538
test30 0.03823457605749547
train35 0.04201207425232707 greater than 0.04242980022471546
test35 0.03617126677664386
train40 0.04005435969032725 greater than 0.0404264528960199
test40 0.03472737432698788
train45 0.03812509350093183 greater than 0.038525493889104964
test45 0.03363766131951854
train50 0.03637955436111008 greater than 0.03670074791230222
test50 0.03326032064768412
train55 0.03496610476653051 greater than 0.035227783112448424
test55 0.032639289330766166
train60 0.03363837813193225 greater than 0.03387696556157389
test60 0.03165032913582451
train65 0.032894120616483606 greater than 0.03301232278499712
test65 0.03144234360329423
train70 0.03227968728608052 greater than 0.03239565662881469
test70 0.03200260415001207
train75 0.031710244060879 greater than 0.03180886310544446
test75 0.03246796964807345
train80 0.031334022358949574 greater than 0.03143037099189791
test80 0.032826157793844325
train85 0.030905649492224734 greater than 0.030972158271726023
test85 0.03328261704164611
train90 0.03062062134187287 greater than 0.030714445585282916
test90 0.033673613514536384
train95 0.030278950807447 greater than 0.030345348388258763
test95 0.034036299637829406
train100 0.029811060589264485 greater than 0.02992971907702337
test100 0.034377645648365686
train105 0.028975044555598375 greater than 0.029144014037845466
test105 0.034769538407103076
train110 0.02855938908561627 greater than 0.02863289671863486
test110 0.034835770030815845
train115 0.027862068362938825 greater than 0.027969932569172146
test115 0.03485306444965119
train120 0.027229778642010323 greater than 0.027409367134309477
test120 0.035151548432825516
train125 0.02665159550738062 greater than 0.02674217936410061
test125 0.03601893907874092
train130 0.026183128426784354 greater than 0.026293090878765097
test130 0.03628379872174787
train135 0.02568186557757612 greater than 0.025755675107727458
test135 0.03648017623055279
train140 0.02546041131293558 greater than 0.025494382483479926
test140 0.03660986615596565
train145 0.025116669989346977 greater than 0.025211388515931986
test145 0.03647570554290589
train150 0.024669402794091057 greater than 0.02477477503593511
test150 0.03644085141776634
train155 0.024090897857601178 greater than 0.02420420860148207
test155 0.03638324002867938
train160 0.023642579759620568 greater than 0.02372702104292972
test160 0.03661221453033116
train165 0.023269523362390576 greater than 0.023332830973138676
test165 0.03673096798367452
train170 0.022959477421010524 greater than 0.023013050123451124
test170 0.03635045882363146
train171 0.0229605148147801 greater than 0.022959477421010524
test171 0.03634092529104973
1 Accuracy:0.9108910891089109 Lower Bound:0.8948513036132367 Upper Bound:0.9269308746045851
Loss calculated for layer count:1 node count: 10 stepSize:0.2 Momentum: True
train0 0.12050273421095377 greater than 1
test0 0.10497056288278392
train5 0.0640485629263263 greater than 0.06799609889349859
test5 0.08351885888716074
train10 0.05532944524316695 greater than 0.056579063480019176
test10 0.058711914659507716
train15 0.05062349861534579 greater than 0.051633784448078285
test15 0.05193858715189373
train20 0.04729974549403913 greater than 0.04776773115271085
test20 0.04541191646936447
train25 0.04468835574897335 greater than 0.045123159573709076
test25 0.04188219423067218
train30 0.04309455662079863 greater than 0.04342767878200859
test30 0.04015405099374719
train35 0.04198847255732588 greater than 0.042136520432412894
test35 0.03756170276873342
train40 0.04085499992797544 greater than 0.041105356994909546
test40 0.034676629860170706
train45 0.039955709830082085 greater than 0.040137359137036296
test45 0.03280530580734012
train50 0.037770652023481247 greater than 0.03807449440758075
test50 0.032501399415810366
train55 0.0358105883374551 greater than 0.036349846930802815
test55 0.03237315472282652
train60 0.03430968584217477 greater than 0.034444031954216046
test60 0.032345950537671
train65 0.03303781297746964 greater than 0.03334722341321174
test65 0.032363944539683165
train70 0.03224826081443757 greater than 0.03237043533575687
test70 0.032386187028408765
train75 0.031546207472898435 greater than 0.03170966782360074
test75 0.03296137995303072
train80 0.030530116776703274 greater than 0.030799019092229606
test80 0.03399208420803891
train85 0.029640682743117503 greater than 0.03000900190421895
test85 0.03575024186024728
train87 0.029221550578875384 greater than 0.02922144685602335
test87 0.036760021377557475
1 Accuracy:0.9067656765676567 Lower Bound:0.8903959958211952 Upper Bound:0.9231353573141182
Loss calculated for layer count:1 node count: 10 stepSize:0.2 Momentum: False
train0 0.12273275272021134 greater than 1
test0 0.11098179668226589
train5 0.06632787339423361 greater than 0.07029607345951795
test5 0.08019946492388275
train10 0.05727180341681695 greater than 0.05845336362735706
test10 0.07060066216262952
train15 0.053239092649239005 greater than 0.0538788937428302
test15 0.06377782500877126
train20 0.05057793710561225 greater than 0.051060911031239255
test20 0.05824967110074159
train25 0.04842542928490385 greater than 0.04882176128483564
test25 0.05360167571393565
train30 0.0466893388042974 greater than 0.04700596957259791
test30 0.04991380870131946
train35 0.0452548513129219 greater than 0.0455294123609333
test35 0.047136106936635995
train40 0.043914409651993454 greater than 0.044177794709789824
test40 0.04493059080373795
train45 0.04265746709933288 greater than 0.04290079865091048
test45 0.04308526546664571
train50 0.04142614742157684 greater than 0.04168455464513781
test50 0.041158499834696764
train55 0.03961299793031114 greater than 0.0400782160824418
test55 0.039204027875342475
train60 0.037557694907718535 greater than 0.03792434267515346
test60 0.03784343114931851
train65 0.03581062077560475 greater than 0.036161188754520034
test65 0.03701301097069459
train70 0.03430054941119294 greater than 0.03460570679848079
test70 0.03627205714972926
train75 0.03259896456736224 greater than 0.03296483512827515
test75 0.035399485543017674
train80 0.03095948707928919 greater than 0.03123122057828974
test80 0.034579145741720774
train85 0.029512107464422434 greater than 0.029793180253600008
test85 0.03393068283144254
train90 0.02837042101623638 greater than 0.028574242444022655
test90 0.0333742151786551
train95 0.027564733281449247 greater than 0.027707278672764058
test95 0.03307294890625052
train100 0.02687561923072504 greater than 0.027010346427595585
test100 0.03301532792122075
train105 0.026284886468097946 greater than 0.026388694295548375
test105 0.03316246054399836
train110 0.02579968623201271 greater than 0.02589936008691733
test110 0.03337790274853104
train115 0.02540692632563266 greater than 0.025463429113579742
test115 0.03352674154460312
train120 0.025175674756203446 greater than 0.025218655343565193
test120 0.03380051485267977
train125 0.02485048391973278 greater than 0.02497706666973815
test125 0.033955539407064264
train129 0.02473861043768128 greater than 0.024583397735828995
test129 0.034509584563542216
2 Accuracy:0.9133663366336634 Lower Bound:0.897529421057252 Upper Bound:0.9292032522100748
Loss calculated for layer count:1 node count: 10 stepSize:0.2 Momentum: True
train0 0.12273275272021134 greater than 1
test0 0.11098179668226589
train5 0.06612405649357178 greater than 0.0705653620471115
test5 0.08639490330621552
train10 0.05663748036823384 greater than 0.057950737942865725
test10 0.06904224159234433
train15 0.05147576170218858 greater than 0.05237220322705194
test15 0.05953105464455599
train20 0.04727228423107449 greater than 0.048124703506560035
test20 0.0524050407016422
train25 0.043692656272906534 greater than 0.04433281769088212
test25 0.04572606852784833
train30 0.040775983717142784 greater than 0.0414075421497361
test30 0.04053658746408865
train35 0.0381671015341531 greater than 0.03864502501986661
test35 0.03760480416188753
train40 0.03577115370485294 greater than 0.03619451941867931
test40 0.0363057143570099
train45 0.0340340225492489 greater than 0.03435076071107971
test45 0.03545767641777841
train50 0.03262332259020706 greater than 0.03288781145568486
test50 0.03342114839070088
train55 0.031008767598169677 greater than 0.031175421168948572
test55 0.03250068997935515
train60 0.030001383659075526 greater than 0.030024227468847177
test60 0.03196275406991022
train65 0.02883444240307076 greater than 0.029020381586868784
test65 0.03179418031726676
train70 0.028010645040490757 greater than 0.02809223859650621
test70 0.03174081042296376
train71 0.028049733673261242 greater than 0.028010645040490757
test71 0.03173909982278848
2 Accuracy:0.9216171617161716 Lower Bound:0.9064853638655583 Upper Bound:0.9367489595667848
Loss calculated for layer count:1 node count: 10 stepSize:0.2 Momentum: False
train0 0.12435093436909354 greater than 1
test0 0.11495099823600134
train5 0.06837196981858645 greater than 0.072538295497487
test5 0.08577031777639832
train10 0.05921556375635611 greater than 0.06031713991263709
test10 0.07371834364251832
train15 0.055341992355232475 greater than 0.05596707346742912
test15 0.0668268394281734
train20 0.052825681258380934 greater than 0.0532700930475706
test20 0.06118317872024012
train25 0.0509114219570541 greater than 0.051258897981057566
test25 0.05711756692926774
train30 0.04936477923591253 greater than 0.04965205759219959
test30 0.05412143219908728
train35 0.04806730712047139 greater than 0.04830795378248445
test35 0.051670742558546305
train40 0.047026730709136544 greater than 0.047220337346658696
test40 0.04923012170360771
train45 0.04598500403665401 greater than 0.04620162004942883
test45 0.047096298992062226
train50 0.04490111279391718 greater than 0.045118597462733764
test50 0.0454748396595942
train55 0.043878856276361386 greater than 0.04406988416060777
test55 0.04429790716394083
train60 0.04300889656629301 greater than 0.04317565542089062
test60 0.04340310163481572
train65 0.04216815135173652 greater than 0.042334118888959
test65 0.042692651671153936
train70 0.04131836176784607 greater than 0.041494399168937296
test70 0.041998884889995675
train75 0.040441008049221204 greater than 0.04061041986373922
test75 0.041281713660577
train80 0.0394321670485082 greater than 0.039635983503825564
test80 0.04090485610832207
train85 0.038401766434309884 greater than 0.03860195299044598
test85 0.04061423986234824
train90 0.0375435501826723 greater than 0.037704188239925746
test90 0.04035398588719338
train95 0.03684567654278749 greater than 0.03697200355337704
test95 0.04018150525696244
train100 0.036266292761878025 greater than 0.03637888551002288
test100 0.03986985067930538
train105 0.035727959595642275 greater than 0.03583180682862471
test105 0.039533885415363644
train110 0.0353275514193117 greater than 0.03538209875573871
test110 0.039384469826367736
train115 0.034706544841258756 greater than 0.03482981045429365
test115 0.039258178369616106
train120 0.03411996460430015 greater than 0.03423711960604237
test120 0.039311360750829506
train125 0.033132765418237634 greater than 0.03332805625423663
test125 0.03955499117391618
train130 0.032598508334430794 greater than 0.03273811466908352
test130 0.03979202205133145
train135 0.03180464554452371 greater than 0.031917054689455514
test135 0.03986210489329434
train140 0.031389469806156506 greater than 0.03131941732073888
test140 0.03957725170036208
3 Accuracy:0.8952145214521452 Lower Bound:0.8779712815231102 Upper Bound:0.9124577613811802
Loss calculated for layer count:1 node count: 10 stepSize:0.2 Momentum: True
train0 0.12435093436909354 greater than 1
test0 0.11495099823600134
train5 0.07372010775827326 greater than 0.07824150123524423
test5 0.10187656489754943
train10 0.05934793222307626 greater than 0.06075680913346275
test10 0.09587938959668667
train15 0.05579742228394311 greater than 0.056442415748944895
test15 0.06616235616035686
train20 0.05103825501546434 greater than 0.05187451379841692
test20 0.05800613281837459
train25 0.04874231245823931 greater than 0.0491394187663753
test25 0.05046625955712503
train30 0.046301986022325624 greater than 0.04663142456596113
test30 0.0513611192031752
train35 0.0447685497760554 greater than 0.04499462592969854
test35 0.04292179953487847
train40 0.04298223728606575 greater than 0.04353022779607569
test40 0.041227987790427294
train45 0.03937937444655712 greater than 0.04006587319353337
test45 0.04141009547471971
train50 0.038249872367295934 greater than 0.03814705024266654
test50 0.041083444231487895
3 Accuracy:0.8910891089108911 Lower Bound:0.8735502641153237 Upper Bound:0.9086279537064585
Loss calculated for layer count:1 node count: 10 stepSize:0.2 Momentum: False
train0 0.126120265148459 greater than 1
test0 0.1211210249934343
train5 0.07599281580139683 greater than 0.0811181150023977
test5 0.06199180227366115
train10 0.06361859723785028 greater than 0.06511861275566239
test10 0.05219885484307866
train15 0.058606474132115366 greater than 0.05938785644115512
test15 0.04896627716126945
train20 0.05555149729782033 greater than 0.05607241635383192
test20 0.047159370330552064
train25 0.05338059127041315 greater than 0.05376916465320737
test25 0.04574158848603874
train30 0.05165215265367672 greater than 0.05197541337247746
test30 0.044535917246843804
train35 0.05014822625249602 greater than 0.05043600361617604
test35 0.043503644693647
train40 0.0487899244969893 greater than 0.04905187728778854
test40 0.04260595688952742
train45 0.047539466933723185 greater than 0.04778220070531299
test45 0.04175903310781975
train50 0.046365493010711384 greater than 0.0465978942196522
test50 0.04081930379426867
train55 0.045096348299525926 greater than 0.04537535026626528
test55 0.03963166667213392
train60 0.04347692870713962 greater than 0.04382617002489522
test60 0.0380715688983724
train65 0.041768078953581256 greater than 0.04210112674417752
test65 0.03634790376513708
train70 0.040178000111027595 greater than 0.040497717695612265
test70 0.03453142957070202
train75 0.038614366981558894 greater than 0.038924483836005726
test75 0.03304455770440373
train80 0.037131998704417364 greater than 0.03743605833485458
test80 0.03202133604035011
train85 0.035293012714702 greater than 0.03565294872785805
test85 0.031349398770600806
train90 0.033880347528990225 greater than 0.03413453052726123
test90 0.03078546457762615
train95 0.03251008616444931 greater than 0.03281434317010612
test95 0.030385787853012793
train100 0.03104226850045452 greater than 0.03132913687277447
test100 0.03024387914148771
train105 0.02949453813784668 greater than 0.02980505988154686
test105 0.030359911809268246
train110 0.028037022341329498 greater than 0.028311345831029976
test110 0.030358144252199428
train115 0.02672474999530029 greater than 0.026980460483248585
test115 0.030385459562078138
train120 0.02554318357000418 greater than 0.025753116640375304
test120 0.03059854938754766
train125 0.024548710389198945 greater than 0.024747111881792856
test125 0.031186715583833003
train130 0.023559869990616607 greater than 0.02376282936745675
test130 0.031537293677441444
train135 0.02279493013514589 greater than 0.022900923536978125
test135 0.03305352568048263
train140 0.022070548118070066 greater than 0.022167628033261874
test140 0.030440428130469488
train145 0.02134749933261007 greater than 0.02145308815387868
test145 0.0305862176991913
train150 0.02104369251069047 greater than 0.021154008515748644
test150 0.033754464546569725
train155 0.020510242178375236 greater than 0.02060794516683518
test155 0.033911928130818426
train160 0.02018237691604028 greater than 0.020219410697693743
test160 0.03434680953117267
train165 0.020012710992078304 greater than 0.020086311849871277
test165 0.03535493149938224
train169 0.01964221044318569 greater than 0.019639981728734966
test169 0.03450273836429261
4 Accuracy:0.9092409240924092 Lower Bound:0.8930679726938885 Upper Bound:0.9254138754909299
Loss calculated for layer count:1 node count: 10 stepSize:0.2 Momentum: True
train0 0.126120265148459 greater than 1
test0 0.1211210249934343
train5 0.07681046463839582 greater than 0.08217929325577858
test5 0.05930121983266844
train10 0.06304945273535309 greater than 0.0645188764721347
test10 0.050970324807063705
train15 0.05805043967355407 greater than 0.05890218006127537
test15 0.04798516651835595
train20 0.054446200222822275 greater than 0.055095540303652824
test20 0.04594120311143826
train25 0.05113298382842827 greater than 0.051763803263734164
test25 0.04409798508953805
train30 0.04876034410076522 greater than 0.04918874707121779
test30 0.04244275885972865
train35 0.046471018790665015 greater than 0.046955385282435695
test35 0.03925399587138824
train40 0.04348140319627384 greater than 0.04411336092754776
test40 0.038079895673081815
train45 0.040650079036453256 greater than 0.04120436806119065
test45 0.03585801254682124
train50 0.03816542610267259 greater than 0.038617333146243826
test50 0.03447087829198998
train55 0.03606123603702885 greater than 0.03636243658508727
test55 0.034825687502433735
train60 0.034384275282555964 greater than 0.03483172449933368
test60 0.036345172462533576
train62 0.03424796564680296 greater than 0.03412286410825009
test62 0.0368478389530081
4 Accuracy:0.9051155115511551 Lower Bound:0.8886166349039726 Upper Bound:0.9216143881983376
