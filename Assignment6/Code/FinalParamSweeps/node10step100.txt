Loss calculated for layer count:1 node count: 10 stepSize:0.1 Momentum: False
train0 0.12225387439587389 greater than 1
test0 0.11119293819503731
train5 0.06295624157133979 greater than 0.06677974980161613
test5 0.0667873729743757
train10 0.054673442138869176 greater than 0.05571857910038877
test10 0.05500944641504031
train15 0.05094253460450923 greater than 0.05154769167898326
test15 0.04846249799153654
train20 0.048517114978329355 greater than 0.048940629027297844
test20 0.04449713502873125
train25 0.04668455142906792 greater than 0.04702097132185423
test25 0.04191102843679226
train30 0.045163952457227326 greater than 0.04544856661826977
test30 0.04014725369399754
train35 0.04387260440913725 greater than 0.04411393068974394
test35 0.03883565585201483
train40 0.042778561673534055 greater than 0.04298372155068622
test40 0.037697131315786093
train45 0.04179209979379779 greater than 0.041991452550669495
test45 0.036604626394671214
train50 0.04066063946362186 greater than 0.040909281230087996
test50 0.035554109738318525
train55 0.039241995873471935 greater than 0.03954652233601106
test55 0.03437792740436954
train60 0.03764804733440292 greater than 0.03796332488341571
test60 0.033140815062368274
train65 0.0362364489998046 greater than 0.036501744536354956
test65 0.03226788346675913
train70 0.03498183902652734 greater than 0.03522630128331334
test70 0.031889099776606894
train75 0.033811176769665705 greater than 0.03403238988817309
test75 0.031928509857033764
train80 0.0327583769292343 greater than 0.03296984051408864
test80 0.03219882570365656
train85 0.03185925800395465 greater than 0.032013156610659246
test85 0.03258002570864038
train90 0.03119352916733927 greater than 0.031320066814477784
test90 0.03294711002793108
train95 0.03058287489701473 greater than 0.03070179760943456
test95 0.03341101088752431
train100 0.030015920653158973 greater than 0.030124841770016383
test100 0.033935692998329325
train105 0.02951069212070399 greater than 0.029606917059560787
test105 0.03441208751398455
train110 0.029051899728884403 greater than 0.02914175777005937
test110 0.03482187045549746
train115 0.028610325919061482 greater than 0.0286975703435069
test115 0.03522118666952863
train120 0.028180012168375665 greater than 0.028265717293173096
test120 0.035626251443563337
train125 0.02774750096389121 greater than 0.02783477105255092
test125 0.03603188869378668
train130 0.027306119996116207 greater than 0.027394878141264616
test130 0.036409942014849
train135 0.026861836912395527 greater than 0.026950582140211874
test135 0.03672955139673273
train140 0.026420854776081866 greater than 0.026508575912803978
test140 0.03697469391256746
train145 0.025987817163315736 greater than 0.02607354493886166
test145 0.03713164416202926
train150 0.025564742712809705 greater than 0.02564892128392333
test150 0.037214933084919626
train155 0.025149959419036996 greater than 0.025231208609287927
test155 0.037323849392412345
train160 0.024765030685407734 greater than 0.024839208681406343
test160 0.037452883871912764
train165 0.02441138649508416 greater than 0.024480020770563576
test165 0.0375081230985384
train170 0.0240824720184232 greater than 0.02414641370854001
test170 0.037461760841345275
train175 0.023775010144863804 greater than 0.023835036021752343
test175 0.037340860438193325
train180 0.023482480218347056 greater than 0.023540210618188753
test180 0.037183987963650605
train185 0.023197559297183538 greater than 0.02325404784322216
test185 0.037017856876009975
train190 0.022920130123134375 greater than 0.022974919774433947
test190 0.03685334131488963
train195 0.022649627374499107 greater than 0.022703518460901236
test195 0.03669238718572034
train200 0.02237924292521406 greater than 0.022433280652777585
test200 0.036570304718720296
train205 0.02211619720882331 greater than 0.022167233706670328
test205 0.03650600146366973
train210 0.02188464411817453 greater than 0.021927235017375455
test210 0.03652258488789583
train215 0.02169288009836456 greater than 0.02173037380870864
test215 0.0366928526443946
train220 0.021475241513341025 greater than 0.021521866527631772
test220 0.03703049996014958
train225 0.021311053803795818 greater than 0.021331539464423538
test225 0.03722633031917336
train230 0.021063952725610974 greater than 0.021182824472204577
test230 0.037671036142913304
train235 0.02054146593615589 greater than 0.02060136576171383
test235 0.03793955505614768
train240 0.020253695470342857 greater than 0.020309498596027285
test240 0.037509426143247836
train245 0.019961153641842436 greater than 0.020020848430070695
test245 0.03694593554767271
train250 0.019672107620986014 greater than 0.01972955774240003
test250 0.03634928667527817
train255 0.019393278593147007 greater than 0.01944694276398278
test255 0.035850134442481245
train260 0.019186023331431257 greater than 0.019217738128634042
test260 0.03532051824982193
train265 0.019022527436693647 greater than 0.019073018554940244
test265 0.03530987034082516
train270 0.01872298358250413 greater than 0.01874263213294112
test270 0.036092460810848916
train275 0.018441858490323832 greater than 0.018485373219838112
test275 0.036539276330293156
train280 0.018288676738472214 greater than 0.018286738107132806
test280 0.03585565605296014
0 Accuracy:0.915016501650165 Lower Bound:0.8993169761328473 Upper Bound:0.9307160271674827
Loss calculated for layer count:1 node count: 10 stepSize:0.1 Momentum: True
train0 0.12225387439587389 greater than 1
test0 0.11119293819503731
train5 0.06576502529247112 greater than 0.07023097638875216
test5 0.07542911250665771
train10 0.05613821256796803 greater than 0.057478667049531244
test10 0.05382758491615635
train15 0.04986845144181196 greater than 0.050883018532078016
test15 0.04359494640791257
train20 0.045800468517890866 greater than 0.04647383801692716
test20 0.04037150082437811
train25 0.04408790009498796 greater than 0.044438752000065466
test25 0.04012361509026337
train30 0.04255710904656111 greater than 0.04284925919142786
test30 0.03901612900416722
train35 0.04059196576871628 greater than 0.0410080688780234
test35 0.039830576548083876
train40 0.03895453470807915 greater than 0.03912100859687735
test40 0.03988515168299801
train45 0.03799426427607799 greater than 0.03830252167963752
test45 0.03960552143132594
train50 0.03662997340627846 greater than 0.0368344623308792
test50 0.037928075210557854
train55 0.035160491255044994 greater than 0.03549963739176433
test55 0.03669798004343318
train60 0.033870181918617154 greater than 0.034252401855122204
test60 0.03501863950795743
train65 0.031810489591146913 greater than 0.03228444870885084
test65 0.03425257706034282
train70 0.0293776503354378 greater than 0.029628082508885618
test70 0.035571341615328086
train72 0.029334202775049445 greater than 0.029305332345730184
test72 0.034705313480147715
0 Accuracy:0.9191419141914191 Lower Bound:0.9037937027025817 Upper Bound:0.9344901256802565
Loss calculated for layer count:1 node count: 10 stepSize:0.1 Momentum: False
train0 0.12524669011466685 greater than 1
test0 0.12071741832610026
train5 0.06853774560046266 greater than 0.07372848174609886
test5 0.07239627253476244
train10 0.05727911342998697 greater than 0.0585759350250088
test10 0.062102653656514295
train15 0.05312608613166353 greater than 0.05376137095845276
test15 0.05527376719708294
train20 0.050597733418464665 greater than 0.05104513075369518
test20 0.05031732871361958
train25 0.04866246169086753 greater than 0.049013186505879616
test25 0.04692833749375146
train30 0.047077785252860306 greater than 0.04737759571038939
test30 0.04450442515480303
train35 0.04565250152192203 greater than 0.0459306278530827
test35 0.04258014595971923
train40 0.04426862266764428 greater than 0.04454780372353689
test40 0.040800076788043975
train45 0.04281599231131607 greater than 0.04311467760043167
test45 0.03897424094624757
train50 0.04130410746879296 greater than 0.04160571139924622
test50 0.03718471269079557
train55 0.03980217161544857 greater than 0.040102930670967735
test55 0.035635973558135595
train60 0.03829841678155336 greater than 0.03859795439321297
test60 0.034423906278489395
train65 0.03680931999632768 greater than 0.037107265963847565
test65 0.03350935825428957
train70 0.03535424406504166 greater than 0.035633652035311374
test70 0.03286113799171787
train75 0.034019858319741934 greater than 0.03428293217327928
test75 0.032389305903173085
train80 0.032810515456317996 greater than 0.03303471939235228
test80 0.03209117110170277
train85 0.03183124194367781 greater than 0.0320102817225473
test85 0.03192575898960735
train90 0.031032460040846636 greater than 0.031180913574816636
test90 0.03193610561918826
train95 0.03034385993706397 greater than 0.030476362047382365
test95 0.03207897646203368
train100 0.029706769434203337 greater than 0.029831192324020973
test100 0.03228915118903902
train105 0.029095060738000524 greater than 0.029218516750074145
test105 0.03251281599884458
train110 0.028460172656586204 greater than 0.02858424299400323
test110 0.0327306453810812
train115 0.02788479154984478 greater than 0.02799544507967547
test115 0.032962479192886175
train120 0.027353426236575124 greater than 0.027457144888168524
test120 0.03318361708893331
train125 0.026845598303701302 greater than 0.02694635465570278
test125 0.03337552679137194
train130 0.02634546913908528 greater than 0.026444694655930686
test130 0.033535801692524465
train135 0.025860211367046988 greater than 0.02595579768980131
test135 0.03365642306405716
train140 0.02538916403579108 greater than 0.02548272952090194
test140 0.033702813873149086
train145 0.02492484332310307 greater than 0.025017330606844
test145 0.033620325104195915
train150 0.024458532084098695 greater than 0.024552936081395683
test150 0.03340096773449247
train155 0.023973792500189293 greater than 0.024072376408552084
test155 0.033056145191461606
train160 0.02347393006691647 greater than 0.023574130523242108
test160 0.0326202418753793
train165 0.022984881998775745 greater than 0.02308027802186076
test165 0.03217151647988537
train170 0.022533611472881205 greater than 0.022620356197797023
test170 0.03181909103995482
train175 0.02211695652200804 greater than 0.02219877038878662
test175 0.03155769277168596
train180 0.021717400918056344 greater than 0.021795871696066577
test180 0.03132673070984975
train185 0.021335842133208837 greater than 0.021411044473542695
test185 0.031123879831121845
train190 0.02095537499681165 greater than 0.0210332634734184
test190 0.030934886367334644
train195 0.020547075647306515 greater than 0.020628467570021927
test195 0.030755450663682574
train200 0.02017324442697164 greater than 0.020241866634154514
test200 0.03057666318624181
train205 0.019931335497235345 greater than 0.019968507492489136
test205 0.030379973164020746
train210 0.01946026541233627 greater than 0.01953646602255477
test210 0.03032565273564712
train215 0.019169964230571986 greater than 0.019223457653933868
test215 0.030451102382899966
train220 0.018922594338545203 greater than 0.018968984751281687
test220 0.030596209817427767
train225 0.018714536374847802 greater than 0.01875331079305399
test225 0.03072609899231866
train230 0.018533859183973565 greater than 0.018568793771303282
test230 0.030823947251943106
train235 0.018363180156800316 greater than 0.018396796640515575
test235 0.03089114627969951
train240 0.018202368181889125 greater than 0.018233433497504958
test240 0.030934443384929303
train245 0.018053001700869233 greater than 0.018082307848229538
test245 0.030977196437622062
train250 0.017909361279250503 greater than 0.017937677107922087
test250 0.03104487231181685
train255 0.01777087309917577 greater than 0.01779826197951036
test255 0.03111549507590343
train260 0.017633901976418162 greater than 0.01766139763141757
test260 0.031145979786500896
train265 0.017496765616904414 greater than 0.017523946509991797
test265 0.03113847192327313
train270 0.01736500526512162 greater than 0.017390902541172676
test270 0.03112947514976301
train275 0.01722862084869013 greater than 0.01725787822580859
test275 0.031130409546638114
train280 0.01705634430816001 greater than 0.017094234823113112
test280 0.03114354419580904
train285 0.016857189599563217 greater than 0.016897065250554958
test285 0.031188382971167723
train290 0.016664822061269832 greater than 0.01670221112805939
test290 0.031218692754740197
train295 0.01648917229755542 greater than 0.016523084059060226
test295 0.031229455006483418
train300 0.016316440146505004 greater than 0.016350812838051055
test300 0.03134720043984345
train305 0.01617739006412103 greater than 0.016203064920420344
test305 0.03148095212236273
train310 0.01603318177963335 greater than 0.01606467900518149
test310 0.03159814282461054
train315 0.01585961594793045 greater than 0.015894393968145876
test315 0.03173066068443507
train320 0.01569917230337068 greater than 0.015729283850975845
test320 0.031732466092813744
train325 0.015552780698907837 greater than 0.015585249105203241
test325 0.031603030306278354
train330 0.015377835231581915 greater than 0.015414610058327345
test330 0.03150474261648968
train335 0.015180495493611374 greater than 0.015219736941396663
test335 0.03153427326942307
train340 0.014989190061100546 greater than 0.015026839401431282
test340 0.03162620006353242
train345 0.01481059035143672 greater than 0.014844743536801801
test345 0.0317915325173549
train350 0.01464355197491606 greater than 0.014676636697720055
test350 0.03203916468800453
train355 0.014483328062866185 greater than 0.014514372186351054
test355 0.0321972017338729
train360 0.014339987994622919 greater than 0.014367600014040647
test360 0.032005976491144145
train365 0.014227094106547787 greater than 0.014238448563161924
test365 0.03245029283738303
train370 0.014165806997755078 greater than 0.014187747021454205
test370 0.032227737264881144
train375 0.014011920558909013 greater than 0.014041866602559109
test375 0.032211248478958794
train380 0.013896945435801316 greater than 0.01392862987532206
test380 0.03189960614311262
train385 0.013825763485164401 greater than 0.013817265374087982
test385 0.032088015670270184
1 Accuracy:0.9174917491749175 Lower Bound:0.9020016379834073 Upper Bound:0.9329818603664277
Loss calculated for layer count:1 node count: 10 stepSize:0.1 Momentum: True
train0 0.12524669011466685 greater than 1
test0 0.12071741832610026
train5 0.06753349071268287 greater than 0.07289598136461922
test5 0.07655551036663277
train10 0.05646251835744578 greater than 0.057788827815711916
test10 0.061553252327604356
train15 0.05194605303440362 greater than 0.052671322701104806
test15 0.053343717941031744
train20 0.048989268478401425 greater than 0.049510944258793044
test20 0.0482370746592641
train25 0.046749961332503344 greater than 0.04715573408685225
test25 0.04499970192728591
train30 0.04494929544702917 greater than 0.04528513516208412
test30 0.0423909266839243
train35 0.043359470323872384 greater than 0.04366891729713133
test35 0.039879665908846305
train40 0.04185651972771905 greater than 0.042156842772718646
test40 0.037448405738253296
train45 0.04026688834222529 greater than 0.04059400506500061
test45 0.035340336232838374
train50 0.038721206503439146 greater than 0.039014246791682215
test50 0.03382508842952983
train55 0.03727489301578396 greater than 0.03756611387647344
test55 0.033017062500964915
train60 0.035766826121839616 greater than 0.036060133729950504
test60 0.03244116822091142
train65 0.03438565428658379 greater than 0.034652028738845285
test65 0.03195450870234262
train70 0.03309010305549707 greater than 0.03333961341672122
test70 0.0316002143904629
train75 0.031939159922662476 greater than 0.032161320519036675
test75 0.0314653348063685
train80 0.030873891793158137 greater than 0.03107830992653248
test80 0.031628362355705195
train85 0.02991289881346965 greater than 0.030098470194256745
test85 0.03181369044888804
train90 0.02900710287331389 greater than 0.029191356680185708
test90 0.031962923408979445
train95 0.02811201167183332 greater than 0.028274496137150495
test95 0.032219135625612606
train100 0.027401296791314506 greater than 0.027526042550316362
test100 0.032505544873463584
train105 0.026975898600564714 greater than 0.02708190893148543
test105 0.0328712251506556
train110 0.026231852645876585 greater than 0.0263412743310734
test110 0.033199383370644854
train115 0.025551877915891627 greater than 0.025724751541734085
test115 0.03367358304376689
train120 0.025150449177336852 greater than 0.025177324316058593
test120 0.033472241424979246
train121 0.02515509060651465 greater than 0.025150449177336852
test121 0.03392058336225138
1 Accuracy:0.9100660066006601 Lower Bound:0.8939594335446445 Upper Bound:0.9261725796566757
Loss calculated for layer count:1 node count: 10 stepSize:0.1 Momentum: False
train0 0.12518659582301533 greater than 1
test0 0.12058179673597959
train5 0.07205526389450322 greater than 0.07763023313040314
test5 0.07892670872658406
train10 0.058743432582389614 greater than 0.060241371661772077
test10 0.06793420986180228
train15 0.05410062746002238 greater than 0.054792567385931364
test15 0.06279650164983477
train20 0.051526103408774594 greater than 0.05195505204679756
test20 0.058336923527569085
train25 0.04975563703104392 greater than 0.0500705720496338
test25 0.05462256044899493
train30 0.048378877187640695 greater than 0.048632099254675605
test30 0.05171086849233858
train35 0.047230328865219155 greater than 0.04744736901611562
test35 0.049466831893791426
train40 0.04620061246972848 greater than 0.04640041910959346
test40 0.04759947437054119
train45 0.04522738452454131 greater than 0.0454207501646512
test45 0.04575953954924782
train50 0.04424331738798713 greater than 0.044443750763515553
test50 0.04376449594092889
train55 0.04320199440545877 greater than 0.04341583167475015
test55 0.04185705043894924
train60 0.04209426787093391 greater than 0.04232047994984762
test60 0.040091486551215055
train65 0.04093198884647895 greater than 0.04116833999391389
test65 0.038360665500184424
train70 0.039735925002391544 greater than 0.039975740361979394
test70 0.036704146699431645
train75 0.03854397310226922 greater than 0.03878080482250942
test75 0.035279969083213965
train80 0.03739788784982523 greater than 0.03761980076551179
test80 0.034187296923833974
train85 0.036350572551042584 greater than 0.03655278394500261
test85 0.033387922199880904
train90 0.03537396899989103 greater than 0.03556548054835478
test90 0.03280090624468644
train95 0.03443915904740496 greater than 0.03462358540641601
test95 0.032370543841144614
train100 0.033528619219147106 greater than 0.03370955855069943
test100 0.03205542948454208
train105 0.03262998007651005 greater than 0.03280879334626631
test105 0.031842013363786385
train110 0.03175326366876197 greater than 0.03192526677944617
test110 0.03173398172262387
train115 0.030928234131355075 greater than 0.031088419124571186
test115 0.03171403094959827
train120 0.030160929188467828 greater than 0.03031008505034623
test120 0.03175175101348237
train125 0.0294472245781896 greater than 0.0295856302674739
test125 0.031812538951754184
train130 0.028787742863879355 greater than 0.028915370618005785
test130 0.03186065970238545
train135 0.028179637074795864 greater than 0.028297422584712868
test135 0.03187900061259545
train140 0.027616256336488804 greater than 0.0277257741348302
test140 0.03186313115669183
train145 0.02708879165074395 greater than 0.02719178725613649
test145 0.03181145698963488
train150 0.026591455604507215 greater than 0.026688562776298795
test150 0.031727260904756714
train155 0.026123408004042416 greater than 0.026214796429033495
test155 0.03163303814914237
train160 0.025680382785595805 greater than 0.025767230973456498
test160 0.03157970604879801
train165 0.025260335380477617 greater than 0.02534238865566502
test165 0.031593271647739014
train170 0.024863795239165532 greater than 0.024941393083629394
test170 0.03163529249509656
train175 0.024487126099715754 greater than 0.02456102666858614
test175 0.031684299990632825
train180 0.02412726602150862 greater than 0.024198033860683726
test180 0.03173944326947354
train185 0.0237810755060812 greater than 0.023849393475560816
test185 0.031796282895246664
train190 0.02344477217892619 greater than 0.023511440807688952
test190 0.03184748232720743
train195 0.023114185319304034 greater than 0.02318004074827404
test195 0.03189003931127015
train200 0.02278562224757553 greater than 0.022851297844666045
test200 0.03192841022635852
train205 0.02245724645293586 greater than 0.022522898033089583
test205 0.03196899182671068
train210 0.022132883431747883 greater than 0.022196468993978587
test210 0.031986197982221846
train215 0.021787352525198554 greater than 0.021876483164218433
test215 0.03191515123868971
train220 0.021309681141913034 greater than 0.021397629952342657
test220 0.032140956945275787
train225 0.02090870633431127 greater than 0.0209841998778124
test225 0.032327995361657216
train230 0.02055989247705736 greater than 0.02062603916835848
test230 0.03239018492908175
train235 0.02025645202968888 greater than 0.020313422263878177
test235 0.03239799148774441
train240 0.01999910087019301 greater than 0.020047083560082377
test240 0.032401802769911434
train245 0.019778529353450102 greater than 0.019820776252661095
test245 0.03239364461150919
train250 0.019567717188660325 greater than 0.01961067557331872
test250 0.03233681891170393
train255 0.019342779406768533 greater than 0.01938884576139207
test255 0.03229434381834505
train260 0.019110603061277445 greater than 0.01915708858609783
test260 0.032293286093648045
train265 0.018875778594451092 greater than 0.01892331257714955
test265 0.03228357823780951
train270 0.01863108714882248 greater than 0.018681075983162515
test270 0.03225205357606297
train275 0.018371925437308208 greater than 0.018425071520197296
test275 0.0322182544968441
train280 0.01809579030748963 greater than 0.018152385612094746
test280 0.03219376987598376
train285 0.017803572011403396 greater than 0.017863058172733193
test285 0.03216742754053213
train290 0.017508201686451078 greater than 0.017566077497919014
test290 0.03211868637437466
train295 0.017233324973160373 greater than 0.017286547423594964
test295 0.03205813499240414
train300 0.01697804983069517 greater than 0.0170275777479405
test300 0.03201975714016859
train305 0.01674531439984265 greater than 0.01678965384112511
test305 0.03202442706237887
train310 0.016541525477531117 greater than 0.01657992686653386
test310 0.032071949502991116
train315 0.01636482940671971 greater than 0.016398365159629568
test315 0.03215150709122782
train320 0.016206335930531363 greater than 0.016237113073324653
test320 0.032250393001527426
train325 0.01605541577008431 greater than 0.016085408001672623
test325 0.03235244639746086
train330 0.015905153415412713 greater than 0.015935298802801694
test330 0.032441553380985075
train335 0.015753668527184444 greater than 0.01578404533442589
test335 0.0325080327101527
train340 0.015601704082656206 greater than 0.015632068018130038
test340 0.03254971675531045
train345 0.015450702502547379 greater than 0.015480755232156728
test345 0.03257058355378365
train350 0.01530206686232382 greater than 0.015331545552194082
test350 0.032577891204648074
train355 0.015156972784581179 greater than 0.01518565525498588
test355 0.032579538360287666
train360 0.015016692090122474 greater than 0.015044271788262314
test360 0.032582951763992514
train365 0.014884104867751312 greater than 0.014909720166976058
test365 0.03259469295596128
train370 0.014768316522190118 greater than 0.014789281200281158
test370 0.032622431252829404
train375 0.014700615735920717 greater than 0.014705668589952963
test375 0.03267619283362976
train376 0.014704438257347793 greater than 0.014700615735920717
test376 0.03268610961950815
2 Accuracy:0.9183168316831684 Lower Bound:0.902897437139886 Upper Bound:0.9337362262264507
Loss calculated for layer count:1 node count: 10 stepSize:0.1 Momentum: True
train0 0.12518659582301533 greater than 1
test0 0.12058179673597959
train5 0.07114100008877881 greater than 0.07674270343733497
test5 0.07999086731353212
train10 0.058498580758817316 greater than 0.059895152158949846
test10 0.06903926373319184
train15 0.05405765737397853 greater than 0.05472738821473841
test15 0.06369276885900282
train20 0.051528285231619286 greater than 0.0519571058962178
test20 0.05889431106672762
train25 0.0497088059050699 greater than 0.05003970086347091
test25 0.054900850754771004
train30 0.04819731278847529 greater than 0.04848186854819178
test30 0.05161720583247989
train35 0.04691175667457333 greater than 0.04715491939968268
test35 0.048837169927422396
train40 0.04574886096753698 greater than 0.0459772207324163
test40 0.04630098089671219
train45 0.04460324185563447 greater than 0.044835003755254066
test45 0.0440146158353056
train50 0.043406362455416736 greater than 0.04365080626434597
test50 0.04196866365970802
train55 0.042160445373371234 greater than 0.042412036540134014
test55 0.04005586282648449
train60 0.04088036259520974 greater than 0.041139774840336304
test60 0.03818833333259786
train65 0.03956610995444442 greater than 0.03982999120193718
test65 0.036450045579400604
train70 0.03826532139573986 greater than 0.03852013033168348
test70 0.034992906025498274
train75 0.03707285788308101 greater than 0.03730031719629716
test75 0.03389835086798755
train80 0.0359792880861663 greater than 0.03619511549385764
test80 0.03310142162506292
train85 0.03490662299700497 greater than 0.03511984769888082
test85 0.03252633606638672
train90 0.03386799796184117 greater than 0.034070751499161014
test90 0.032115386275969396
train95 0.03288750851079383 greater than 0.0330808407440973
test95 0.031844166453466397
train100 0.031948954686371336 greater than 0.03213009198138309
test100 0.031756956207285664
train105 0.031132338403775467 greater than 0.031283025777144396
test105 0.03184138302928855
train110 0.030452634737555936 greater than 0.030580725221420874
test110 0.0319788827473486
train115 0.029847171497094344 greater than 0.029964826984048107
test115 0.032066501520249535
train120 0.029275194944288974 greater than 0.02938749903707284
test120 0.032091157229678174
train125 0.02873383512066722 greater than 0.02883906258566075
test125 0.03208349634556866
train130 0.028232757455049703 greater than 0.02832968899581554
test130 0.032068620287993725
train135 0.027769351103676464 greater than 0.02785948983905695
test135 0.03204190684139979
train140 0.02733356718113302 greater than 0.027418980852007786
test140 0.03198928414808269
train145 0.026916108610502684 greater than 0.02699857371307181
test145 0.03190058704298531
train150 0.026506546519757732 greater than 0.026588455897498284
test150 0.031766848130447
train155 0.026095629832778605 greater than 0.02617762325209735
test155 0.03157253828117526
train160 0.025691388469751726 greater than 0.025772087006608883
test160 0.03131186266414189
train165 0.02527520457120877 greater than 0.025360146283187952
test165 0.031050544387448455
train170 0.02484692298140006 greater than 0.0249319058316555
test170 0.03086434093864629
train175 0.024443202096249297 greater than 0.024523445834830744
test175 0.030733361965686837
train180 0.02402247474206223 greater than 0.024107854588545433
test180 0.03059885350098601
train185 0.023603755098233772 greater than 0.023685894562335896
test185 0.030455248449980366
train190 0.023209267142090574 greater than 0.02328570689754361
test190 0.030326193006918266
train195 0.022848142220800005 greater than 0.022917576213156845
test195 0.030218897614741162
train200 0.022519413876411373 greater than 0.022582918933666936
test200 0.030130783940483723
train205 0.022215344789169967 greater than 0.02227457386718113
test205 0.030065170328298512
train210 0.0219284426451783 greater than 0.021984732993370355
test210 0.030028930930893406
train215 0.021654373175708275 greater than 0.021708138454889888
test215 0.030026677320074805
train220 0.021396981163571114 greater than 0.02144659625654875
test220 0.030057275712903214
train225 0.02116742670370159 greater than 0.02121065301749984
test225 0.030113916682703856
train230 0.02097466907716846 greater than 0.021009794415368963
test230 0.03018296308874533
train235 0.020822852328311412 greater than 0.020851266919207575
test235 0.03024372594016637
train240 0.02068852738834805 greater than 0.020711919357672
test240 0.03027964328918141
train245 0.020580729249361884 greater than 0.020605042885318125
test245 0.030294889200117987
train250 0.020388308855658885 greater than 0.020438763910593027
test250 0.030356869688645018
train255 0.020091766902926866 greater than 0.02015219865356571
test255 0.030385764896794017
train260 0.01980621115178623 greater than 0.01986108932416676
test260 0.03035585650542253
train265 0.019546073395310802 greater than 0.019596304815834003
test265 0.030300823781936943
train270 0.019306345935065722 greater than 0.019353007012227596
test270 0.030248328183579094
train275 0.019075867206018254 greater than 0.019122170537422226
test275 0.030207368398548935
train280 0.018840273291262758 greater than 0.018887360056383126
test280 0.030184251571668298
train285 0.01862271634727868 greater than 0.018662789810045027
test285 0.030190751035594973
train290 0.018451466912663837 greater than 0.01848241405333791
test290 0.030235582075164993
train295 0.01829090103467517 greater than 0.01832835077402706
test295 0.030337811907981155
train300 0.018044028635293106 greater than 0.018102162483378842
test300 0.030491264924436542
train305 0.017656457734196326 greater than 0.0177348387414386
test305 0.03054230170420511
train310 0.01735930163184761 greater than 0.01740926060086448
test310 0.03051214467543412
train315 0.017167413710102525 greater than 0.017198583032705845
test315 0.030501826529618938
train320 0.016979122023159557 greater than 0.017022132716056872
test320 0.03053137814439266
train325 0.01675468990961607 greater than 0.01679867491994174
test325 0.03050868513520189
train330 0.01656999707109937 greater than 0.016601046267825086
test330 0.0304351087616454
train335 0.016433942110800768 greater than 0.01646256872303668
test335 0.030352508716512457
train340 0.01621226994916985 greater than 0.016270618618399974
test340 0.030271733373973368
train345 0.015824047028190128 greater than 0.015905335646178607
test345 0.030228488721412688
train350 0.015560278173381086 greater than 0.015601502911785619
test350 0.030252620870914525
train355 0.015374565047351442 greater than 0.015409128016397116
test355 0.030281346710622898
train360 0.015223718982100117 greater than 0.015250828129321855
test360 0.030253586723675077
train365 0.015111451251910704 greater than 0.015130954052856818
test365 0.030218450002114414
train370 0.015025740340521584 greater than 0.015042509269230122
test370 0.030209712301245435
train375 0.014924973672042756 greater than 0.01494840152775324
test375 0.030239796264285967
train380 0.014779986937546624 greater than 0.014812434316647994
test380 0.030312154374902645
train385 0.01459315857374491 greater than 0.01463324983018692
test385 0.03041894293298547
train390 0.01439485439011818 greater than 0.014433616401217549
test390 0.030560920033708323
train395 0.014228600268695126 greater than 0.014279052594331262
test395 0.030328554754253268
train400 0.013988927230386649 greater than 0.013983207036293306
test400 0.03174693174193434
2 Accuracy:0.9174917491749175 Lower Bound:0.9020016379834073 Upper Bound:0.9329818603664277
Loss calculated for layer count:1 node count: 10 stepSize:0.1 Momentum: False
train0 0.1260034264751088 greater than 1
test0 0.12314706995886385
train5 0.0769289649543359 greater than 0.08327311436179004
test5 0.08616571804001973
train10 0.06095020481681098 greater than 0.06279627784121296
test10 0.07144303493397465
train15 0.05572463102716126 greater than 0.056459937239597226
test15 0.06467447640171066
train20 0.0529954520418303 greater than 0.05345290040511226
test20 0.05956194581781752
train25 0.05105381448621588 greater than 0.05141916219063475
test25 0.05532376106878751
train30 0.04941552811522866 greater than 0.04970123321978411
test30 0.05193664700772235
train35 0.04816162015963991 greater than 0.04839499508496012
test35 0.04960465649674129
train40 0.04708567421914151 greater than 0.047290221360523174
test40 0.04782850752078977
train45 0.046127908329664714 greater than 0.046311618019616196
test45 0.04644685303079407
train50 0.04525641342891638 greater than 0.045425211912910025
test50 0.04533605507387258
train55 0.044442709744332336 greater than 0.04460209209439513
test55 0.0443879219234261
train60 0.0436618255982594 greater than 0.04381642106133342
test60 0.043512186590279486
train65 0.04289347122113161 greater than 0.043046939228706865
test65 0.0426299122555528
train70 0.04212277117143306 greater than 0.042277630102803804
test70 0.041680916373092326
train75 0.04133877988195293 greater than 0.04149723397925273
test75 0.040665995885938756
train80 0.0405258237381036 greater than 0.04069187554363986
test80 0.03962605468162901
train85 0.039658979017113315 greater than 0.03983777526892361
test85 0.03857801563774504
train90 0.03872388694155943 greater than 0.038915898072654484
test90 0.03754737485452172
train95 0.03774034820389864 greater than 0.037939115980516726
test95 0.03659150600960583
train100 0.036741913590589065 greater than 0.0369420601034293
test100 0.03576506598734087
train105 0.03572724986908766 greater than 0.03593324647423083
test105 0.03506515244574727
train110 0.03465634696408894 greater than 0.03487687830289869
test110 0.03444591796976258
train115 0.033505747851134526 greater than 0.033741091974101876
test115 0.03387185831433348
train120 0.03233416478535882 greater than 0.032564202642460655
test120 0.03334814711985565
train125 0.03125841740503375 greater than 0.03146174907713234
test125 0.03289954460641333
train130 0.030339464618549163 greater than 0.03051046227541514
test130 0.03253053241608601
train135 0.029571528681678214 greater than 0.029714151139599788
test135 0.032217144792683575
train140 0.02892972410944626 greater than 0.029049627241090736
test140 0.031920597974343455
train145 0.02835494606980707 greater than 0.028471383389303568
test145 0.03160100089383119
train150 0.027666581617506146 greater than 0.027816906756915533
test150 0.03134674312361911
train155 0.027001179764792604 greater than 0.02711897673603332
test155 0.031274265693997126
train160 0.02651480629982324 greater than 0.02659985809510181
test160 0.03130672959949301
train165 0.02614858202016563 greater than 0.026217514642644647
test165 0.031472557905410765
train170 0.02578381294204723 greater than 0.02585621358973912
test170 0.03179651087200483
train175 0.025589859444765654 greater than 0.02563381959091036
test175 0.03229760186419824
train180 0.025236459156986107 greater than 0.025306099923613105
test180 0.03280390559376448
train185 0.024857480962362427 greater than 0.024944279416294252
test185 0.033140407551879
train190 0.02434218156788533 greater than 0.02444296749132527
test190 0.03342839016966406
train195 0.023931064957082537 greater than 0.024004659902977513
test195 0.03368722856784602
train200 0.02359944844046971 greater than 0.02366152317318172
test200 0.03390518121125884
train205 0.023317833497046643 greater than 0.023370416172520742
test205 0.03410119607376762
train210 0.02308084766458059 greater than 0.02312521643067271
test210 0.034277330662595716
train215 0.022857034490436575 greater than 0.022904636201543902
test215 0.03442839910958861
train220 0.02259476066418303 greater than 0.022651428743477208
test220 0.034552824926196574
train225 0.022246237200535143 greater than 0.022313402692710732
test225 0.03466458669927798
train230 0.021940145807365745 greater than 0.02199868124900396
test230 0.03466509676219801
train235 0.021681648028249706 greater than 0.02172900609484985
test235 0.03468597372268431
train240 0.02140948893312862 greater than 0.02147851497825147
test240 0.03484246359965329
train245 0.020824158247820513 greater than 0.02093626813384308
test245 0.03514359563075253
train250 0.020517540615162814 greater than 0.02056039415073697
test250 0.03528892000055119
train255 0.02028363064680823 greater than 0.020338540719337966
test255 0.03539432359907194
train260 0.019941655431920585 greater than 0.020019558181932337
test260 0.03546542529072856
train265 0.019624703894698555 greater than 0.019678828257404503
test265 0.035711287913725555
train270 0.01938765029715307 greater than 0.019432419028331878
test270 0.035847892176824894
train275 0.019172981790518157 greater than 0.019211522664046826
test275 0.03597280862917962
train279 0.019103567621971684 greater than 0.019088926962665287
test279 0.03614623089535249
3 Accuracy:0.9075907590759076 Lower Bound:0.8912862586847559 Upper Bound:0.9238952594670593
Loss calculated for layer count:1 node count: 10 stepSize:0.1 Momentum: True
train0 0.1260034264751088 greater than 1
test0 0.12314706995886385
train5 0.07626142582504969 greater than 0.0825775678578626
test5 0.0873089361170135
train10 0.06065936153565346 greater than 0.06240348697255574
test10 0.0718868477404174
train15 0.05569290054067264 greater than 0.05640313528541868
test15 0.0651684720056206
train20 0.052967922852495485 greater than 0.05344713918477875
test20 0.05968403312243326
train25 0.05087038783374416 greater than 0.05122939528589313
test25 0.055075365739412956
train30 0.04933408806514961 greater than 0.04961548684502717
test30 0.05193311061450087
train35 0.04806155303899065 greater than 0.048300573538547116
test35 0.049568092872860195
train40 0.0469570235090543 greater than 0.04716716539851175
test40 0.04776304737886126
train45 0.045971218196223865 greater than 0.046160661277592205
test45 0.046361117523584155
train50 0.045068683408667515 greater than 0.04524407693966866
test50 0.045220651758007574
train55 0.04421838966358264 greater than 0.04438560705654187
test55 0.044216931282543975
train60 0.04339411519540293 greater than 0.04355795550145967
test60 0.04324451004639977
train65 0.04257585501206921 greater than 0.04273972035424561
test65 0.04222395171396405
train70 0.041751114849830455 greater than 0.041917040728843544
test70 0.04114618632139689
train75 0.0409070606907887 greater than 0.041078542672770973
test75 0.040058806854261754
train80 0.040014859810943756 greater than 0.040198931737982016
test80 0.038964259822520435
train85 0.0390442388385313 greater than 0.03924496897611284
test85 0.0378648123912032
train90 0.038005387976583295 greater than 0.03821635578335961
test90 0.03682010718836441
train95 0.03695032661224917 greater than 0.03716017900022413
test95 0.03591741392260038
train100 0.03590690806637114 greater than 0.03611628102118143
test100 0.03517703848504545
train105 0.03482585087844143 greater than 0.035048006589908025
test105 0.034549757846700904
train110 0.033668940437483134 greater than 0.03390577828279685
test110 0.0339721842637336
train115 0.03246663825101774 greater than 0.03270695751718258
test115 0.03342452776714631
train120 0.031320654407063095 greater than 0.031538793335114314
test120 0.032928100418181755
train125 0.030337114974262103 greater than 0.030519968659918528
test125 0.03248775883215948
train130 0.02950058406626343 greater than 0.029659324984074073
test130 0.032086622704967614
train135 0.02873559790678047 greater than 0.028892948891693273
test135 0.03166710685446481
train140 0.027838093779877685 greater than 0.02801145556300753
test140 0.03130725763647609
train145 0.027116432510313048 greater than 0.027248040544426956
test145 0.031023472213764353
train150 0.026500078476100777 greater than 0.026616443714747334
test150 0.03081411024168808
train155 0.025969653226546454 greater than 0.026069284293996783
test155 0.030701874758880688
train160 0.025492116364414404 greater than 0.02558659487501105
test160 0.030707515326520295
train165 0.025220582357950664 greater than 0.025223555273735515
test165 0.030835695229455985
train170 0.024830720106273876 greater than 0.02492454279534118
test170 0.031088742595209114
train175 0.024455190289628084 greater than 0.024526819343596757
test175 0.03140504812470042
train180 0.024091299001502895 greater than 0.024167028707066576
test180 0.03177165610571447
train185 0.02371485180971227 greater than 0.023831094107278586
test185 0.03215340583337306
train190 0.02316265753837461 greater than 0.023209992573954594
test190 0.032390578266277746
train195 0.022876219808161097 greater than 0.022967246540628195
test195 0.032483087281951525
train200 0.022445313985947065 greater than 0.022522397804676488
test200 0.03270884497815551
train205 0.022094150469942044 greater than 0.022161912878426653
test205 0.03299966821803699
train210 0.02175671994968391 greater than 0.021824615661804995
test210 0.03327474028455409
train215 0.021409535624809895 greater than 0.02148021575894229
test215 0.033514838766601336
train220 0.021045075865912838 greater than 0.02111926448212417
test220 0.03375577352652055
train225 0.020658067543172353 greater than 0.02074061386302954
test225 0.034073439955652055
train230 0.020322960312564947 greater than 0.02037403335703001
test230 0.034054168037487224
train235 0.02010103862301196 greater than 0.020143994059574823
test235 0.03396186228343853
train240 0.019892497088595994 greater than 0.019933059373939715
test240 0.03393449530500329
train245 0.019698994720886036 greater than 0.019737014450468708
test245 0.033975548098806624
train250 0.01948735234019779 greater than 0.019534334401768258
test250 0.03407741780333894
train255 0.01946099225917402 greater than 0.019357935218958813
test255 0.03442203849469612
3 Accuracy:0.9100660066006601 Lower Bound:0.8939594335446445 Upper Bound:0.9261725796566757
Loss calculated for layer count:1 node count: 10 stepSize:0.1 Momentum: False
train0 0.1263336349045839 greater than 1
test0 0.12459721108383827
train5 0.08750538323347519 greater than 0.09566125772543152
test5 0.07862137023854843
train10 0.06791005189685247 greater than 0.07053062791400302
test10 0.06017628375826756
train15 0.06017826920111088 greater than 0.06123167133708963
test15 0.05272953200290408
train20 0.05655453731520181 greater than 0.057133414614842254
test20 0.049367110628014035
train25 0.054216173599579205 greater than 0.05462793531813067
test25 0.04745516737921227
train30 0.052445115615783564 greater than 0.05276618184489686
test30 0.04613489169100955
train35 0.051029618654426546 greater than 0.05129062950508457
test35 0.045115342836348216
train40 0.04985161517980865 greater than 0.05007241060761133
test40 0.04426344313473363
train45 0.04883218145698838 greater than 0.04902633407903987
test45 0.043513362205403784
train50 0.04791446700884906 greater than 0.04809212509052615
test50 0.042838593432726155
train55 0.047053806829258166 greater than 0.047223340773285306
test55 0.042224529714570753
train60 0.0462086206671694 greater than 0.04637849624748902
test60 0.04164551470453928
train65 0.045336508833201276 greater than 0.04551488312486834
test65 0.04104902704203481
train70 0.04440720271863627 greater than 0.044598256972728435
test70 0.04035182669125909
train75 0.04340994690999743 greater than 0.04361549404547684
test75 0.039469610941918455
train80 0.04232027051251026 greater than 0.04254788228232796
test80 0.03838076669386533
train85 0.04109284356510375 greater than 0.04135069694023122
test85 0.03717451739616783
train90 0.039718601178978366 greater than 0.04000371862930592
test90 0.03598870737347963
train95 0.03823577150080837 greater than 0.0385384237355744
test95 0.034910594235132604
train100 0.036707694493088035 greater than 0.03701284544617792
test100 0.033981448370744426
train105 0.035219760558877974 greater than 0.03551057613383234
test105 0.03321381039773047
train110 0.033825651402790494 greater than 0.03409673750456323
test110 0.03259758666748757
train115 0.032517532718655144 greater than 0.03277345063883666
test115 0.03211717737787569
train120 0.03128361929273619 greater than 0.0315234047330949
test120 0.03175693557095985
train125 0.03015554815097522 greater than 0.030370679557176775
test125 0.03149704010511372
train130 0.02916292498219589 greater than 0.029350718052175803
test130 0.03131090017838412
train135 0.028292404602949694 greater than 0.028458341368692863
test135 0.031168773991631694
train140 0.027510970145546612 greater than 0.027661548544173
test140 0.031046257156314767
train145 0.026792552975487983 greater than 0.02693208657890298
test145 0.03093020308627012
train150 0.02612081971865766 greater than 0.0262519705849802
test150 0.03081594717643002
train155 0.025486916799981912 greater than 0.02561081982338766
test155 0.030702617548141745
train160 0.02489032561422265 greater than 0.025006394908011046
test160 0.03059303892996738
train165 0.024339850280889436 greater than 0.024445388794572313
test165 0.030494400259410855
train170 0.02386001351227323 greater than 0.02394860312775588
test170 0.030413836517139307
train175 0.02345400647883488 greater than 0.02353446384706007
test175 0.030351837099384105
train180 0.02299643813341846 greater than 0.023100304097488134
test180 0.03029226719183784
train185 0.022412093070178322 greater than 0.022528680532344986
test185 0.030206371365589048
train190 0.021901635937946407 greater than 0.021994968899396804
test190 0.03011338413310674
train195 0.02146246044745544 greater than 0.02154872130235937
test195 0.030033498155603838
train200 0.021025188116347904 greater than 0.021113991906957744
test200 0.029962625021518585
train205 0.020570463440400987 greater than 0.020662628072969636
test205 0.02989065264272977
train210 0.02010467181078817 greater than 0.020198188715048214
test210 0.029810115795641166
train215 0.01963973632071746 greater than 0.019731982113344957
test215 0.029720392936712536
train220 0.019189353380806712 greater than 0.019277699119672514
test220 0.029627979712149186
train225 0.018763310740227013 greater than 0.018846328199820985
test225 0.029539671758819084
train230 0.018364839769094036 greater than 0.01844237151348555
test230 0.029453194858793354
train235 0.01799183579463945 greater than 0.018064603709116913
test235 0.029358738777424346
train240 0.017640149957728096 greater than 0.017708960023804437
test240 0.02925652259065785
train245 0.01730590001121966 greater than 0.017371581000165674
test245 0.02916721446900978
train250 0.01698415768165482 greater than 0.01704772081455456
test250 0.029119575860880667
train255 0.0166721788576112 greater than 0.016733717354875628
test255 0.029135740613577633
train260 0.01637286063565492 greater than 0.016431473124455316
test260 0.029217865295984496
train265 0.01609057666949386 greater than 0.016145549075239112
test265 0.029340168499194467
train270 0.015826750056739208 greater than 0.015878086726454025
test270 0.029463967397021267
train275 0.01557973891870259 greater than 0.015627934024846645
test275 0.029561808684384898
train280 0.015346539169022245 greater than 0.015392223712792287
test280 0.029626434563474573
train285 0.01512426777610629 greater than 0.015167954450367185
test285 0.029664058758667417
train290 0.014911124018672882 greater than 0.014953061691168053
test290 0.02968452663470183
train295 0.014706639562269207 greater than 0.01474683259140315
test295 0.02969588969449285
train300 0.014511141813374701 greater than 0.014549501437326041
test300 0.029703476768522384
train305 0.014324968520634525 greater than 0.014361453599348177
test305 0.02971093453368746
train310 0.01414808400807273 greater than 0.01418272992325984
test310 0.029721245161303995
train315 0.013980222006491827 greater than 0.014013085187647687
test315 0.02973692692682871
train320 0.01382114742609407 greater than 0.013852268806188759
test320 0.029759669956938052
train325 0.013670608646800963 greater than 0.013700054501154127
test325 0.029790074439433222
train330 0.013528002898644321 greater than 0.013555938397396952
test330 0.029827837490578494
train335 0.013392108298893575 greater than 0.013418830677992646
test335 0.029872254204799303
train340 0.01326111639945334 greater than 0.013287021355870513
test340 0.02992264791608511
train345 0.013132997879930927 greater than 0.013158481065228671
test345 0.02997840127512917
train350 0.013006130683550877 greater than 0.01303145149485262
test350 0.030038684041744663
train355 0.012879849721147111 greater than 0.012905057604369212
test355 0.030102385824380642
train360 0.012754267500461042 greater than 0.012779323936120824
test360 0.030168441627274733
train365 0.012629069788632053 greater than 0.012654146750173834
test365 0.030236124461205473
train370 0.012502271056326614 greater than 0.012527908685927012
test370 0.03030520682844955
train375 0.012370746871756225 greater than 0.012397563731724648
test375 0.03037601058040807
train380 0.012232174909356103 greater than 0.012260519755662575
test380 0.030448783707078313
train385 0.012084989433692997 greater than 0.012115232560072126
test385 0.030523172045922985
train390 0.011925997062585247 greater than 0.011958962430660953
test390 0.030599539404035918
train395 0.01175127647336868 greater than 0.011787512240308285
test395 0.03068056013471056
train400 0.011564616763472844 greater than 0.011602147625581564
test400 0.030769851045726847
train405 0.011385917190911627 greater than 0.011419851160327944
test405 0.030866276126046647
train410 0.011232166107259725 greater than 0.01126098940648828
test410 0.030961151899813036
train415 0.011097748208634801 greater than 0.01112362641586124
test415 0.031047252124502506
train420 0.01097297668060699 greater than 0.010997442361264475
test420 0.031124101442321975
train425 0.010853230410344217 greater than 0.01087687584413406
test425 0.03119365920016689
train430 0.010736980488648568 greater than 0.010759977273285341
test430 0.031257596742301025
train435 0.01062380443482991 greater than 0.010646203179669968
test435 0.031317140103496566
train440 0.010513522358231669 greater than 0.010535354391174362
test440 0.03137317506611432
train445 0.010405996884101666 greater than 0.010427286542839108
test445 0.031426193929572424
train450 0.010301141826642633 greater than 0.010321901055614653
test450 0.0314763238973297
train455 0.010198938991100763 greater than 0.010219166036521036
test455 0.03152353183113229
train460 0.010099434445256013 greater than 0.010119115257784162
test460 0.03156789497628634
train465 0.01000273569157138 greater than 0.010021843571435901
test465 0.031609792777056674
train470 0.009909020145330839 greater than 0.009927513437782455
test470 0.031649963398000844
train475 0.0098185442850498 greater than 0.009836365369393566
test475 0.03168946837619521
train480 0.009731637236674298 greater than 0.009748715475903419
test480 0.03172966610705394
train485 0.009648677109221517 greater than 0.009664934223074123
test485 0.03177229408508842
train490 0.009570070439731147 greater than 0.009585423085448509
test490 0.03181967721737254
train495 0.009496251202541744 greater than 0.009510610495030321
test495 0.031874924918987954
train500 0.009427646893932502 greater than 0.009440934543458412
test500 0.03194182632536616
4 Accuracy:0.9249174917491749 Lower Bound:0.9100811904648197 Upper Bound:0.9397537930335301
Loss calculated for layer count:1 node count: 10 stepSize:0.1 Momentum: True
train0 0.1263336349045839 greater than 1
test0 0.12459721108383827
train5 0.08465924938092456 greater than 0.09208374120187925
test5 0.07123883375961083
train10 0.0656000926051034 greater than 0.06786707789851727
test10 0.054901346563284124
train15 0.059354023392985206 greater than 0.060237507771380136
test15 0.04995985515472583
train20 0.05599732946450479 greater than 0.0565674326090411
test20 0.04784315942139806
train25 0.053618408322842516 greater than 0.05404169675702939
test25 0.046424309593738056
train30 0.051783313626589535 greater than 0.0521187606483092
test30 0.045257335264785314
train35 0.05027815118218609 greater than 0.05055959874622629
test35 0.04425598191769121
train40 0.04898246521240301 greater than 0.04922846307686353
test40 0.04338970483206186
train45 0.047824577433053225 greater than 0.04804864845997538
test45 0.04261936695992464
train50 0.046726095804343545 greater than 0.046944922493597385
test50 0.04187828817406072
train55 0.045620698774819377 greater than 0.0458437474394466
test55 0.04105484128648323
train60 0.04448700844433798 greater than 0.04471680923908958
test60 0.03998770046088658
train65 0.043285384008398514 greater than 0.04353638356915404
test65 0.03856724382392496
train70 0.041864106439449864 greater than 0.04217534313209323
test70 0.03684931644025056
train75 0.04019139824685525 greater than 0.04052932298903884
test75 0.03505993073103001
train80 0.03850805323258767 greater than 0.03884650618164173
test80 0.03356900385088615
train85 0.03678333947124014 greater than 0.0371365758039867
test85 0.032421903814690824
train90 0.034887986126687594 greater than 0.03528347423786617
test90 0.03162188822515517
train95 0.03295105344867808 greater than 0.033320350546434035
test95 0.03114120804861376
train100 0.03128232694145077 greater than 0.03158797150619635
test100 0.03092402337737759
train105 0.029995078809052483 greater than 0.030225854630888914
test105 0.030966863362517794
train110 0.028988404188329566 greater than 0.02917376881463479
test110 0.03108452957465843
train115 0.028125717737731065 greater than 0.028288988258871675
test115 0.031114985631493498
train120 0.027406475420086326 greater than 0.027538271369664434
test120 0.03118907894363115
train125 0.02681686883149665 greater than 0.026925703051395165
test125 0.031401940047325334
train130 0.026305946030421693 greater than 0.026410936542123693
test130 0.031553664942995586
train135 0.025725160595721146 greater than 0.025834626425851957
test135 0.03149713345318729
train140 0.0250871007927191 greater than 0.025254938447893935
test140 0.0313577089529001
train145 0.024523203589652126 greater than 0.02458549576128587
test145 0.031303728008645997
train150 0.02418882390566372 greater than 0.024260164830109676
test150 0.030953680889534808
train155 0.023725246412496685 greater than 0.02383481904932349
test155 0.030822739593018317
train160 0.023032101299237 greater than 0.02318563931834202
test160 0.03104076564496468
train165 0.022216008035391165 greater than 0.022373368452021335
test165 0.03141713894853902
train170 0.021902040502660345 greater than 0.021889614921357256
test170 0.03271105376726764
4 Accuracy:0.9174917491749175 Lower Bound:0.9020016379834073 Upper Bound:0.9329818603664277
